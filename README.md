# About
This repository is for learning how language models work. It contains the implementation, training, and usage details for generating text with a NanoGPT model.

# Running the NanoGPT Model

## 1. Running on Hugging Face
- Visit the <a href="https://huggingface.co/spaces/surya54101q/Thy_Sonnet">Generating Interface</a>.
- Enter your prompt and adjust settings to generate text remotely.

## 2. Downloading the Model Weights
- Go to the <a href="https://huggingface.co/spaces/surya54101q/Thy_Sonnet/tree/main">Download Weights</a> page.
- Download the `thy_sonnet.pt` file.
- Save it in the project root: `./Build GPT/`.

## 3. Running the Model Locally
- Ensure Python, PyTorch, and Gradio are installed.
- Open a terminal in `./Build GPT/`.
- Run: `python generate_model.py`
- A Gradio interface will launch locally allowing you to enter prompts and generate text.


## Sample Generated Text
The following example is generated content from the file  [more.txt](./more.txt):

```
CLARENCE:
Being are cheerfully, my lord, thy son isle:
That mock'd I had lived an eminess, I revenge
To have my brother's accused assured,
Indeed, over, and so remedy that our rest,
Which being eased, and what dost mine shop
A sails hath for to kenel, in some boots his.
...
...
```
Refer to the full generated output in [more.txt](./more.txt).